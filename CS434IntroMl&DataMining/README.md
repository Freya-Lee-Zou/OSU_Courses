<h1>CS434 Machine Leanring and Data Mining</h1>

# Course Syllabus

## Course Overview:

This course provides a broad introduction to machine learning and data mining, focusing on classic topics including supervised learning (discriminative/generative learning, neural networks, support vector
machines); unsupervised learning (clustering, dimensionality reduction); ensemble learning (bagging, boosting); and fundamental issues in applying machine learning (model selection, evaluation). Lectures will discuss general issues in these topics and well-established algorithms, both from a computational aspect (how to compute the answer) and a statistical aspect (how to ensure that future predictions are accurate). Note this class does not cover deep learning.
## Learning Objectives of the Course:

1. Be able to formulate machine learning problems corresponding to different applications.
2. Understand a range of machine learning algorithms along with their strengths and weaknesses.
3. Understand the basic theory underlying machine learning.
4. Be able to apply machine learning algorithms to solve problems of moderate complexity.

## Textbook and materials:

There is no required textbook for this course. Reading materials and lecture slides will be posted on Canvas. Here are some recommended textbooks and resources:
[A Course in Machine Learning by Hal Daume III] (http://ciml.info/)
[Pattern recognition and machine learning] (https://www.microsoft.com/en-
us/research/people/cmbishop/#prml-book) , by Chris Bishop. 1st edition. (CB) 
Machine learning, by Tom Mitchell (TM)
The following resources would be helpful for reviewing some of the important concepts that will be used throughout the course:
Probability:
[A brief review of basic probability concepts] (http://cs229.stanford.edu/section/cs229-
prob.pdf) from Andrew Ng's standford ML class (http://cs229.stanford.edu/) webpage.
Linear algebra:
A geometric review of linear algebra (http://www.cns.nyu.edu/~eero/NOTES/geomLinAlg.pdf)
A brief review of linear algebra (http://cs229.stanford.edu/section/cs229-linalg.pdf)
from Andrew Ng's standford ML class (http://cs229.stanford.edu/) 
[Math for Machine Learning] (http://www.umiacs.umd.edu/~hal/courses/2013S
ML/math4ml.pdf) by Hal Daume III 
Matrix Cookbook (https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf) a great reference for matrix related derivations.
If you prefer watching to reading when reviewing background concepts, here are some useful video lectures
[Khan Academy video lecture on vectors, matrices and spaces]
(https://www.khanacademy.org/math/linear-algebra/vectors and spaces)

F2023)
https://canvas.oregonstate.edu/courses/1933759/assignments/syllabus 3/5
Khan Academy video lecture on random variable and probability distributions
(https://www.khanacademy.org/math/probability/random-variables-
topic/random
_
variables
_prob
_
dist/v/random-variables)
Other machine learning courses
Andrew Ng's ML class at Standford (http://cs229.stanford.edu/)
Tom Mitchel's ML lectures (with video) at CMU
(http://www.cs.cmu.edu/~tom/10701
_
sp11/lectures.shtml)
CMU ML course materials over the years. (http://www.cs.cmu.edu/~tom/10701
_
sp11/prev.shtml)

## additional resources posted by professor" ##

-- Pattern Recognition and Machine Learning -- Christopher Bishop (https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)
-- The "Probabilistic Machine Learning" trilogy -- Kevin Murphy (https://probml.github.io/pml-book/)

Reinforcement Learning:

-- Reinforcement Learning: An Introduction -- Sutton and Barto (http://incompleteideas.net/book/the-book-2nd.html)

Deep Learning:

-- Deep Learning -- Goodfellow, Bengio, Courville (https://www.deeplearningbook.org/)
-- The Little Book of Deep Learning -- Francois Fleuret (https://fleuret.org/public/lbdl.pdf) 
